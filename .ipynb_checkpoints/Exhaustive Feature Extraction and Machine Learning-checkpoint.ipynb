{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tugas akhir nlp",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9hsoBd1r9Lt",
        "outputId": "adb09dc0-bbb6-4dc7-9ecb-253b20bc9103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        }
      },
      "source": [
        "!pip install fuzzywuzzy\n",
        "!pip install PySastrawi\n",
        "!pip install num2words\n",
        "!pip install catboost\n",
        "!pip install python-Levenshtein\n",
        "!git clone https://github.com/adnanzulkarnain/Tesaurus-Bahasa/\n",
        "!git clone https://github.com/riochr17/Daftar-Antonim-Tesaurus-Bahasa-Indonesia/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n",
            "Collecting PySastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/84/b0a5454a040f81e81e6a95a5d5635f20ad43cc0c288f8b4966b339084962/PySastrawi-1.2.0-py2.py3-none-any.whl (210kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: PySastrawi\n",
            "Successfully installed PySastrawi-1.2.0\n",
            "Collecting num2words\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words) (0.6.2)\n",
            "Installing collected packages: num2words\n",
            "Successfully installed num2words-0.5.10\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 60kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.23.2\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (47.3.1)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144792 sha256=f7dd7de131a90efeca7c8dc019e6c6466c704249f90c3fea5b9b46ab8e2d0141\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.0\n",
            "Cloning into 'Tesaurus-Bahasa'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 40 (delta 17), reused 40 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n",
            "Cloning into 'Daftar-Antonim-Tesaurus-Bahasa-Indonesia'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 16\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qNKLV62CfxH",
        "outputId": "3177f0a9-713c-49f4-f780-8801fa1b3154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lloJZApUCyfK"
      },
      "source": [
        "drivedir = 'drive/My Drive/Proyek Akhir NLP/'\n",
        "# Uncomment jika tidak menggunakan drive\n",
        "# drivedir = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSgV0ifhGq2T"
      },
      "source": [
        "# sinonim\n",
        "\n",
        "with open('Tesaurus-Bahasa/Tesaurus-BahasaIndonesia.txt') as f:\n",
        "    lines = f.readlines()\n",
        "lines = [x.strip().split(',') for x in lines]\n",
        "lines = [x for x in lines if len(x) > 1]\n",
        "synonym = dict()\n",
        "for line in lines:\n",
        "    resultant = line[0]\n",
        "    for token in line:\n",
        "        synonym[token] = resultant\n",
        "\n",
        "synonym['tak'] = 'tidak'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOMn61djOZEB"
      },
      "source": [
        "# antonim\n",
        "\n",
        "with open('Daftar-Antonim-Tesaurus-Bahasa-Indonesia/hasil-pasangan-antonim-id.txt') as f:\n",
        "    lines = f.readlines()\n",
        "lines = [x.strip().split() for x in lines]\n",
        "from collections import defaultdict\n",
        "\n",
        "antonym = defaultdict(set)\n",
        "for line in lines:\n",
        "    if line[0] not in antonym.keys():\n",
        "        antonym[line[0]] = {line[1]}\n",
        "    else:\n",
        "        antonym[line[0]].add(line[1])\n",
        "    if line[1] not in antonym.keys():\n",
        "        antonym[line[1]] = {line[0]}\n",
        "    else:\n",
        "        antonym[line[1]].add(line[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWmnl2hSawPh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9TwlehDtESD"
      },
      "source": [
        "train = pd.read_csv(f'{drivedir}training_data.csv',index_col='id')\n",
        "test = pd.read_csv(f'{drivedir}testing_data.csv',index_col='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpWuuENHKEKK"
      },
      "source": [
        "train['label'] = train['label'].apply(lambda x: str(x).lower()).replace('netral','neutral').replace('entailments','entailment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxTBZZHcKP-b",
        "outputId": "2705977b-429a-47f1-b73b-610f05d33d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(set(train['label']))\n",
        "assert(len(set(train['label']))==3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'entailment', 'neutral', 'contradiction'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgwDlnhctK9W",
        "outputId": "5590efb5-ce7a-4945-8b7a-625cc804d997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)\n",
        "print(train.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6726, 3)\n",
            "(6993, 2)\n",
            "Index(['premis', 'hipotesis', 'label'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRrHzbMQtTf9",
        "outputId": "abeee46c-d1a4-4df1-e54c-07d596868e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "display(train.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premis</th>\n",
              "      <th>hipotesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ahli paleontologi Thomas MÃ¶rs dan timnya seda...</td>\n",
              "      <td>Thomas MÃ¶rs adalah ahli paleontologi .</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ahli paleontologi Thomas MÃ¶rs dan timnya seda...</td>\n",
              "      <td>Thomas MÃ¶rs memimpin timnya dengan baik .</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ahli paleontologi Thomas MÃ¶rs dan timnya seda...</td>\n",
              "      <td>Thomas MÃ¶rs seorang diri sedang dalam misi un...</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'Biaya yang diperlukan saat itu adalah sebesar...</td>\n",
              "      <td>Biaya yang diperlukan bernilai dolar saat itu</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Biaya yang diperlukan saat itu adalah sebesar...</td>\n",
              "      <td>Biaya itu belum terkumpul</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               premis  ...          label\n",
              "id                                                     ...               \n",
              "0   Ahli paleontologi Thomas MÃ¶rs dan timnya seda...  ...     entailment\n",
              "1   Ahli paleontologi Thomas MÃ¶rs dan timnya seda...  ...        neutral\n",
              "2   Ahli paleontologi Thomas MÃ¶rs dan timnya seda...  ...  contradiction\n",
              "3   'Biaya yang diperlukan saat itu adalah sebesar...  ...     entailment\n",
              "4   'Biaya yang diperlukan saat itu adalah sebesar...  ...        neutral\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "punN1G0g7-41"
      },
      "source": [
        "def stem(df):\n",
        "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    df['premis'] = df['premis'].apply(stemmer.stem)\n",
        "    df['hipotesis'] = df['hipotesis'].apply(stemmer.stem)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBox_5cVJw50"
      },
      "source": [
        "def map2synonym(df, after_stem=False):\n",
        "    def map2syn(row):\n",
        "        res = []\n",
        "        for tok in row.split():\n",
        "            if tok in synonym.keys():\n",
        "                res.append(synonym[tok])\n",
        "            else:\n",
        "                res.append(tok)\n",
        "        return ' '.join(res)\n",
        "\n",
        "    df['premis'] = df['premis'].apply(map2syn)\n",
        "    df['hipotesis'] = df['hipotesis'].apply(map2syn)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jyKiXZwPRnV"
      },
      "source": [
        "def cont_antonym(df, after_stem=False):\n",
        "    cont_antonym = []\n",
        "    for p, h in zip(df['premis'],df['hipotesis']):\n",
        "        ants = set()\n",
        "        cnt = 0\n",
        "        for tok in p.split():\n",
        "            if tok in antonym.keys():\n",
        "                for k in antonym[tok]:\n",
        "                    ants.add(k)\n",
        "        for ant in ants:\n",
        "            if ant in h.split():\n",
        "                cnt += 1\n",
        "        cont_antonym.append(cnt)\n",
        "    if after_stem:\n",
        "        df['cont_antonym_stem'] = cont_antonym\n",
        "    else:\n",
        "        df['cont_antonym'] = cont_antonym\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTuLdTZ_HWoc"
      },
      "source": [
        "def lowercase(df):\n",
        "    df['premis'] = df['premis'].apply(lambda x: x.lower())\n",
        "    df['hipotesis'] = df['hipotesis'].apply(lambda x: x.lower())\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNeN0v9tB6Cv"
      },
      "source": [
        "def num2word(df):\n",
        "    from num2words import num2words\n",
        "    def num2word_row(row):\n",
        "        sent = []\n",
        "        for word in row.split():\n",
        "            try:\n",
        "                sent.append(num2words(int(word), lang='id'))\n",
        "            except:\n",
        "                sent.append(word)\n",
        "        return ' '.join(sent)\n",
        "    df['premis'] = df['premis'].apply(num2word_row)\n",
        "    df['hipotesis'] = df['hipotesis'].apply(num2word_row)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV-9S2RvMRD1"
      },
      "source": [
        "def del_tanda(df):\n",
        "    def del_tanda_row(row):\n",
        "        return ''.join(ch for ch in row if ch.isalnum() or ch == ' ')\n",
        "    df['premis'] = df['premis'].apply(del_tanda_row)\n",
        "    df['hipotesis'] = df['hipotesis'].apply(del_tanda_row)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3KeBn8KuOCr"
      },
      "source": [
        "def extract_base_feats(df):\n",
        "    df['intersect'] = [set(hip.split()).intersection(set(premis.split())) for hip,premis in zip(df['hipotesis'].values, df['premis'].values)]\n",
        "    df['p_len'] = df['premis'].apply(len)\n",
        "    df['h_len'] = df['hipotesis'].apply(len)\n",
        "    df['p_word_len'] = df['premis'].apply(lambda x: len(x.split()))\n",
        "    df['h_word_len'] = df['hipotesis'].apply(lambda x: len(x.split()))\n",
        "    df['p_unique_word_len'] = df['premis'].apply(lambda x: len(set(x.split())))\n",
        "    df['h_unique_word_len'] = df['hipotesis'].apply(lambda x: len(set(x.split())))\n",
        "    df['i_len'] = df['intersect'].apply(len)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJwxnXBwkBH-"
      },
      "source": [
        "def rat_feats(df):\n",
        "    df['ph_len_rat'] = df['p_len'] / df['h_len']\n",
        "    df['ph_word_len_rat'] = df['p_word_len'] / df['h_word_len']\n",
        "    df['ph_unique_word_len_rat'] = df['p_unique_word_len'] / df['h_unique_word_len']\n",
        "    df['ip_unique_word_len_rat'] = df['i_len'] / df['p_unique_word_len']\n",
        "    df['ih_unique_word_len_rat'] = df['i_len'] / df['h_unique_word_len']\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpF9TsHsjvPX"
      },
      "source": [
        "def neg_feats(df):\n",
        "    def contains_neg(seq):\n",
        "        cnt = 0\n",
        "        for neg_token in ['bukan','tidak','tak','engga','enggak']:\n",
        "            if neg_token in seq:\n",
        "                cnt += 1\n",
        "        return cnt\n",
        "    df['p_contains_neg'] = df['premis'].apply(lambda x: contains_neg(x.split()))\n",
        "    df['h_contains_neg'] = df['hipotesis'].apply(lambda x: contains_neg(x.split()))\n",
        "    df['i_contains_neg'] = df['intersect'].apply(lambda x: contains_neg(x))\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WygKda3Sk96x"
      },
      "source": [
        "def pos_feats(df):\n",
        "    def contains_pos(seq):\n",
        "        cnt = 0\n",
        "        for pos_token in ['adalah','merupakan','iyalah']:\n",
        "            if pos_token in seq:\n",
        "                cnt += 1\n",
        "        return cnt\n",
        "    df['p_contains_pos'] = df['premis'].apply(lambda x: contains_pos(x.split()))\n",
        "    df['h_contains_pos'] = df['hipotesis'].apply(lambda x: contains_pos(x.split()))\n",
        "    df['i_contains_pos'] = df['intersect'].apply(lambda x: contains_pos(x))\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cChMZ6Pza-HN"
      },
      "source": [
        "def fuzzy(df):\n",
        "    from fuzzywuzzy import fuzz\n",
        "    df['ratio'] = [fuzz.ratio(p,h) for p,h in zip(df['premis'],df['hipotesis'])]\n",
        "    df['partial_ratio'] = [fuzz.partial_ratio(p,h) for p,h in zip(df['premis'],df['hipotesis'])]\n",
        "    df['token_sort_ratio'] = [fuzz.token_sort_ratio(p,h) for p,h in zip(df['premis'],df['hipotesis'])]\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMw4RoJOCWbL"
      },
      "source": [
        "def h_is_ordered_subs(df):\n",
        "    is_ordered_subs = []\n",
        "    for p,h, i in zip(df['premis'], df['hipotesis'], df['intersect']):\n",
        "        if len(i) == 0:\n",
        "            is_ordered_subs.append(0)\n",
        "            continue\n",
        "\n",
        "        i_list = []\n",
        "        for p_t in p.split():\n",
        "            if p_t in i:\n",
        "                i_list.append(p_t)\n",
        "\n",
        "        h_list = h.split()\n",
        "\n",
        "        breaked = False\n",
        "        for cnt, i_t in enumerate(i_list):\n",
        "            if len(h_list) == 0:\n",
        "                breaked = True\n",
        "                is_ordered_subs.append((cnt)/len(i_list))\n",
        "                break\n",
        "            elif i_t in h_list:\n",
        "                i_t_index = h_list.index(i_t)\n",
        "                h_list = h_list[i_t_index+1:]\n",
        "            else:\n",
        "                breaked = True\n",
        "                is_ordered_subs.append((cnt)/len(i_list))\n",
        "                break\n",
        "\n",
        "        if not breaked:\n",
        "            is_ordered_subs.append(1)\n",
        "    df['is_ordered_subs_num'] = is_ordered_subs\n",
        "    df['is_ordered_subs_bool'] = df['is_ordered_subs_num'].apply(lambda x: 1 if x == 1 else 0)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE-UXR2Qoxsl"
      },
      "source": [
        "def intersect_position(df):\n",
        "    p_maxx = []\n",
        "    p_minn = []\n",
        "    p_meann = []\n",
        "    h_maxx = []\n",
        "    h_minn = []\n",
        "    h_meann = []\n",
        "    ph_minn = []\n",
        "    ph_maxx = []\n",
        "    ph_meann = []\n",
        "    for p,h, i in zip(df['premis'], df['hipotesis'], df['intersect']):\n",
        "        if len(i) == 0:\n",
        "            p_maxx.append(0)\n",
        "            p_minn.append(0)\n",
        "            p_meann.append(0)\n",
        "            h_maxx.append(0)\n",
        "            h_minn.append(0)\n",
        "            h_meann.append(0)\n",
        "            ph_maxx.append(0)\n",
        "            ph_minn.append(0)\n",
        "            ph_meann.append(0)\n",
        "            continue\n",
        "\n",
        "        p_split = p.split()\n",
        "        p_list = []\n",
        "        for ii in i:\n",
        "            p_list.append(p_split.index(ii))\n",
        "        \n",
        "        p_list = np.array(p_list)\n",
        "        p_maxx.append(p_list.max())\n",
        "        p_minn.append(p_list.min())\n",
        "        p_meann.append(p_list.mean())\n",
        "\n",
        "        h_split = h.split()\n",
        "        h_list = []\n",
        "        for ii in i:\n",
        "            h_list.append(h_split.index(ii))\n",
        "        \n",
        "        h_list = np.array(h_list)\n",
        "        h_maxx.append(h_list.max())\n",
        "        h_minn.append(h_list.min())\n",
        "        h_meann.append(h_list.mean())\n",
        "\n",
        "        ph_maxx.append(h_list.max() - p_list.max())\n",
        "        ph_minn.append(h_list.min() - p_list.min())\n",
        "        ph_meann.append(h_list.mean() - p_list.mean())\n",
        "\n",
        "\n",
        "    df['p_max'] = p_maxx\n",
        "    df['p_min'] = p_minn\n",
        "    df['p_mean'] = p_meann\n",
        "    df['h_max'] = h_maxx\n",
        "    df['h_min'] = h_minn\n",
        "    df['h_mean'] = h_meann\n",
        "    df['ph_max'] = ph_maxx\n",
        "    df['ph_min'] = ph_minn\n",
        "    df['ph_mean'] = ph_meann\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJx8xKqVWbGK"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "def normalize(train, test):\n",
        "    scaler = StandardScaler()\n",
        "    train_data = scaler.fit_transform(train)\n",
        "    test_data = scaler.transform(test)\n",
        "    train = pd.DataFrame(data=train_data, index=train.index, columns=train.columns)\n",
        "    test = pd.DataFrame(data=test_data, index=test.index, columns=test.columns)\n",
        "    return train, test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0STCMFDcNzoB"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-h_p5hDBm3A",
        "outputId": "2f5d1b6a-5ce7-4d47-bea8-8bd846d09a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "train_X = train[['premis','hipotesis']]\n",
        "train_y = train['label']\n",
        "\n",
        "train_X_temp = train_X.copy(deep=True)\n",
        "test_X_temp = test.copy(deep=True)\n",
        "\n",
        "train_X_temp = lowercase(train_X_temp)\n",
        "test_X_temp = lowercase(test_X_temp)\n",
        "\n",
        "train_X_temp = del_tanda(train_X_temp)\n",
        "test_X_temp = del_tanda(test_X_temp)\n",
        "\n",
        "train_X_temp = map2synonym(train_X_temp)\n",
        "test_X_temp = map2synonym(test_X_temp)\n",
        "\n",
        "train_X_temp = cont_antonym(train_X_temp)\n",
        "test_X_temp = cont_antonym(test_X_temp)\n",
        "\n",
        "train_X_temp = stem(train_X_temp)\n",
        "test_X_temp = stem(test_X_temp)\n",
        "\n",
        "train_X_temp = map2synonym(train_X_temp, after_stem=True)\n",
        "test_X_temp = map2synonym(test_X_temp, after_stem=True)\n",
        "\n",
        "train_X_temp = cont_antonym(train_X_temp, after_stem=True)\n",
        "test_X_temp = cont_antonym(test_X_temp, after_stem=True)\n",
        "\n",
        "train_X_temp = num2word(train_X_temp)\n",
        "test_X_temp = num2word(test_X_temp)\n",
        "\n",
        "display(train_X_temp.head())\n",
        "train_X_temp.to_csv('temp.csv')\n",
        "\n",
        "train_X_preproc = train_X_temp.copy(deep=True)\n",
        "test_X_preproc = test_X_temp.copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premis</th>\n",
              "      <th>hipotesis</th>\n",
              "      <th>cont_antonym</th>\n",
              "      <th>cont_antonym_stem</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ahli paleontologi thomas m rs dan tim sedang d...</td>\n",
              "      <td>thomas m rs adalah ahli paleontologi</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ahli paleontologi thomas m rs dan tim sedang d...</td>\n",
              "      <td>thomas m rs pimpin tim dengan baik</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ahli paleontologi thomas m rs dan tim sedang d...</td>\n",
              "      <td>thomas m rs orang diri sedang dalam misi untuk...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>biaya yang perlu saat itu adalah besar enam be...</td>\n",
              "      <td>biaya yang perlu nila dolar saat itu</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>biaya yang perlu saat itu adalah besar enam be...</td>\n",
              "      <td>biaya itu belum kumpul</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               premis  ... cont_antonym_stem\n",
              "id                                                     ...                  \n",
              "0   ahli paleontologi thomas m rs dan tim sedang d...  ...                 1\n",
              "1   ahli paleontologi thomas m rs dan tim sedang d...  ...                 0\n",
              "2   ahli paleontologi thomas m rs dan tim sedang d...  ...                 2\n",
              "3   biaya yang perlu saat itu adalah besar enam be...  ...                 0\n",
              "4   biaya yang perlu saat itu adalah besar enam be...  ...                 0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am15s6hxN275"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj4f6S3fNw2r",
        "outputId": "6d4a0405-f3c3-4680-cec8-00133f5955d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "train_X_temp = train_X_preproc\n",
        "test_X_temp = test_X_preproc\n",
        "\n",
        "train_X_temp = extract_base_feats(train_X_temp)\n",
        "test_X_temp = extract_base_feats(test_X_temp)\n",
        "\n",
        "train_X_temp = neg_feats(train_X_temp)\n",
        "test_X_temp = neg_feats(test_X_temp)\n",
        "\n",
        "train_X_temp = pos_feats(train_X_temp)\n",
        "test_X_temp = pos_feats(test_X_temp)\n",
        "\n",
        "train_X_temp = rat_feats(train_X_temp)\n",
        "test_X_temp = rat_feats(test_X_temp)\n",
        "\n",
        "train_X_temp = intersect_position(train_X_temp)\n",
        "test_X_temp = intersect_position(test_X_temp)\n",
        "\n",
        "train_X_temp = fuzzy(train_X_temp)\n",
        "test_X_temp = fuzzy(test_X_temp)\n",
        "\n",
        "train_X_temp = h_is_ordered_subs(train_X_temp)\n",
        "test_X_temp = h_is_ordered_subs(test_X_temp)\n",
        "\n",
        "display(train_X_temp.head())\n",
        "print(train_X_temp.shape)\n",
        "\n",
        "train_X_copy = train_X_temp.copy(deep=True)\n",
        "test_X_copy = test_X_temp.copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premis</th>\n",
              "      <th>hipotesis</th>\n",
              "      <th>cont_antonym</th>\n",
              "      <th>cont_antonym_stem</th>\n",
              "      <th>intersect</th>\n",
              "      <th>p_len</th>\n",
              "      <th>h_len</th>\n",
              "      <th>p_word_len</th>\n",
              "      <th>h_word_len</th>\n",
              "      <th>p_unique_word_len</th>\n",
              "      <th>h_unique_word_len</th>\n",
              "      <th>i_len</th>\n",
              "      <th>p_contains_neg</th>\n",
              "      <th>h_contains_neg</th>\n",
              "      <th>i_contains_neg</th>\n",
              "      <th>p_contains_pos</th>\n",
              "      <th>h_contains_pos</th>\n",
              "      <th>i_contains_pos</th>\n",
              "      <th>ph_len_rat</th>\n",
              "      <th>ph_word_len_rat</th>\n",
              "      <th>ph_unique_word_len_rat</th>\n",
              "      <th>ip_unique_word_len_rat</th>\n",
              "      <th>ih_unique_word_len_rat</th>\n",
              "      <th>p_max</th>\n",
              "      <th>p_min</th>\n",
              "      <th>p_mean</th>\n",
              "      <th>h_max</th>\n",
              "      <th>h_min</th>\n",
              "      <th>h_mean</th>\n",
              "      <th>ph_max</th>\n",
              "      <th>ph_min</th>\n",
              "      <th>ph_mean</th>\n",
              "      <th>ratio</th>\n",
              "      <th>partial_ratio</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>is_ordered_subs_num</th>\n",
              "      <th>is_ordered_subs_bool</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ahli paleontologi thomas m rs dan tim sedang d...</td>\n",
              "      <td>thomas m rs adalah ahli paleontologi</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>{ahli, paleontologi, rs, m, thomas}</td>\n",
              "      <td>119</td>\n",
              "      <td>36</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.305556</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2.400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>35</td>\n",
              "      <td>58</td>\n",
              "      <td>45</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ahli paleontologi thomas m rs dan tim sedang d...</td>\n",
              "      <td>thomas m rs pimpin tim dengan baik</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{m, tim, rs, thomas}</td>\n",
              "      <td>119</td>\n",
              "      <td>34</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1.750</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>38</td>\n",
              "      <td>68</td>\n",
              "      <td>37</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ahli paleontologi thomas m rs dan tim sedang d...</td>\n",
              "      <td>thomas m rs orang diri sedang dalam misi untuk...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>{temu, untuk, belum, dalam, beku, huni, fosil,...</td>\n",
              "      <td>119</td>\n",
              "      <td>104</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.144231</td>\n",
              "      <td>1.111111</td>\n",
              "      <td>1.111111</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>11.125000</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>9.125</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>88</td>\n",
              "      <td>96</td>\n",
              "      <td>89</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>biaya yang perlu saat itu adalah besar enam be...</td>\n",
              "      <td>biaya yang perlu nila dolar saat itu</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{saat, perlu, yang, dolar, biaya, itu}</td>\n",
              "      <td>85</td>\n",
              "      <td>36</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.361111</td>\n",
              "      <td>2.285714</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>3.833333</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3.000</td>\n",
              "      <td>-7</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.833333</td>\n",
              "      <td>60</td>\n",
              "      <td>69</td>\n",
              "      <td>60</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>biaya yang perlu saat itu adalah besar enam be...</td>\n",
              "      <td>biaya itu belum kumpul</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{biaya, itu}</td>\n",
              "      <td>85</td>\n",
              "      <td>22</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.863636</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>-3</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>32</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               premis  ... is_ordered_subs_bool\n",
              "id                                                     ...                     \n",
              "0   ahli paleontologi thomas m rs dan tim sedang d...  ...                    0\n",
              "1   ahli paleontologi thomas m rs dan tim sedang d...  ...                    1\n",
              "2   ahli paleontologi thomas m rs dan tim sedang d...  ...                    1\n",
              "3   biaya yang perlu saat itu adalah besar enam be...  ...                    0\n",
              "4   biaya yang perlu saat itu adalah besar enam be...  ...                    0\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(6726, 37)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sud_C4QUS7rE",
        "outputId": "be69f123-826a-42df-b7ed-287290adc21a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "print(train_X_copy[train_X_copy['cont_antonym']==1].shape)\n",
        "train_X_copy.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(656, 37)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cont_antonym</th>\n",
              "      <th>cont_antonym_stem</th>\n",
              "      <th>p_len</th>\n",
              "      <th>h_len</th>\n",
              "      <th>p_word_len</th>\n",
              "      <th>h_word_len</th>\n",
              "      <th>p_unique_word_len</th>\n",
              "      <th>h_unique_word_len</th>\n",
              "      <th>i_len</th>\n",
              "      <th>p_contains_neg</th>\n",
              "      <th>h_contains_neg</th>\n",
              "      <th>i_contains_neg</th>\n",
              "      <th>p_contains_pos</th>\n",
              "      <th>h_contains_pos</th>\n",
              "      <th>i_contains_pos</th>\n",
              "      <th>ph_len_rat</th>\n",
              "      <th>ph_word_len_rat</th>\n",
              "      <th>ph_unique_word_len_rat</th>\n",
              "      <th>ip_unique_word_len_rat</th>\n",
              "      <th>ih_unique_word_len_rat</th>\n",
              "      <th>p_max</th>\n",
              "      <th>p_min</th>\n",
              "      <th>p_mean</th>\n",
              "      <th>h_max</th>\n",
              "      <th>h_min</th>\n",
              "      <th>h_mean</th>\n",
              "      <th>ph_max</th>\n",
              "      <th>ph_min</th>\n",
              "      <th>ph_mean</th>\n",
              "      <th>ratio</th>\n",
              "      <th>partial_ratio</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>is_ordered_subs_num</th>\n",
              "      <th>is_ordered_subs_bool</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "      <td>6726.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.139607</td>\n",
              "      <td>0.218555</td>\n",
              "      <td>138.370651</td>\n",
              "      <td>50.339578</td>\n",
              "      <td>22.532114</td>\n",
              "      <td>8.207553</td>\n",
              "      <td>19.712162</td>\n",
              "      <td>7.984092</td>\n",
              "      <td>5.880613</td>\n",
              "      <td>0.122361</td>\n",
              "      <td>0.232233</td>\n",
              "      <td>0.032709</td>\n",
              "      <td>0.141243</td>\n",
              "      <td>0.092328</td>\n",
              "      <td>0.030925</td>\n",
              "      <td>3.062801</td>\n",
              "      <td>3.069389</td>\n",
              "      <td>2.750733</td>\n",
              "      <td>0.330339</td>\n",
              "      <td>0.721664</td>\n",
              "      <td>14.819358</td>\n",
              "      <td>2.988552</td>\n",
              "      <td>8.881138</td>\n",
              "      <td>6.678561</td>\n",
              "      <td>0.292150</td>\n",
              "      <td>3.465878</td>\n",
              "      <td>-8.140797</td>\n",
              "      <td>-2.696402</td>\n",
              "      <td>-5.415260</td>\n",
              "      <td>45.786798</td>\n",
              "      <td>67.884478</td>\n",
              "      <td>50.398454</td>\n",
              "      <td>0.591365</td>\n",
              "      <td>0.311924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.410623</td>\n",
              "      <td>0.514001</td>\n",
              "      <td>95.332457</td>\n",
              "      <td>21.543111</td>\n",
              "      <td>15.561006</td>\n",
              "      <td>3.472296</td>\n",
              "      <td>9.988237</td>\n",
              "      <td>3.130502</td>\n",
              "      <td>3.165594</td>\n",
              "      <td>0.335794</td>\n",
              "      <td>0.422640</td>\n",
              "      <td>0.177887</td>\n",
              "      <td>0.348298</td>\n",
              "      <td>0.289510</td>\n",
              "      <td>0.173127</td>\n",
              "      <td>2.351440</td>\n",
              "      <td>2.517558</td>\n",
              "      <td>1.756622</td>\n",
              "      <td>0.178426</td>\n",
              "      <td>0.203158</td>\n",
              "      <td>10.610450</td>\n",
              "      <td>4.890414</td>\n",
              "      <td>6.694031</td>\n",
              "      <td>3.623489</td>\n",
              "      <td>0.781089</td>\n",
              "      <td>1.858960</td>\n",
              "      <td>9.875866</td>\n",
              "      <td>4.907472</td>\n",
              "      <td>6.557343</td>\n",
              "      <td>15.062705</td>\n",
              "      <td>12.912789</td>\n",
              "      <td>16.217518</td>\n",
              "      <td>0.334636</td>\n",
              "      <td>0.463313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.613636</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-136.000000</td>\n",
              "      <td>-99.000000</td>\n",
              "      <td>-100.666667</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.835668</td>\n",
              "      <td>1.857143</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.625000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>-11.000000</td>\n",
              "      <td>-4.000000</td>\n",
              "      <td>-7.500000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.482451</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.166667</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-3.714286</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.533333</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.428571</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.112745</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>338.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.424242</td>\n",
              "      <td>84.500000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>101.666667</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>15.851852</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cont_antonym  ...  is_ordered_subs_bool\n",
              "count   6726.000000  ...           6726.000000\n",
              "mean       0.139607  ...              0.311924\n",
              "std        0.410623  ...              0.463313\n",
              "min        0.000000  ...              0.000000\n",
              "25%        0.000000  ...              0.000000\n",
              "50%        0.000000  ...              0.000000\n",
              "75%        0.000000  ...              1.000000\n",
              "max        4.000000  ...              1.000000\n",
              "\n",
              "[8 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKrqrbo2sp2k"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzefABYDtGZy",
        "outputId": "2f2184ba-515e-47f6-f95d-27fb18d0756a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "for col in train_X_copy.columns:\n",
        "    print(col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "premis\n",
            "hipotesis\n",
            "cont_antonym\n",
            "cont_antonym_stem\n",
            "intersect\n",
            "p_len\n",
            "h_len\n",
            "p_word_len\n",
            "h_word_len\n",
            "p_unique_word_len\n",
            "h_unique_word_len\n",
            "i_len\n",
            "p_contains_neg\n",
            "h_contains_neg\n",
            "i_contains_neg\n",
            "p_contains_pos\n",
            "h_contains_pos\n",
            "i_contains_pos\n",
            "ph_len_rat\n",
            "ph_word_len_rat\n",
            "ph_unique_word_len_rat\n",
            "ip_unique_word_len_rat\n",
            "ih_unique_word_len_rat\n",
            "p_max\n",
            "p_min\n",
            "p_mean\n",
            "h_max\n",
            "h_min\n",
            "h_mean\n",
            "ph_max\n",
            "ph_min\n",
            "ph_mean\n",
            "ratio\n",
            "partial_ratio\n",
            "token_sort_ratio\n",
            "is_ordered_subs_num\n",
            "is_ordered_subs_bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMUYyWnpsnIt"
      },
      "source": [
        "def select(train_X):\n",
        "    return train_X.drop([\n",
        "                         'premis',\n",
        "                         'hipotesis',\n",
        "                         'intersect',\n",
        "\n",
        "                        #  'h_unique_word_len',\n",
        "                        # 'cont_antonym',\n",
        "                        # 'p_contains_neg',\n",
        "                        'is_ordered_subs_bool',\n",
        "                        # 'i_contains_neg',\n",
        "                         ],axis=1)\n",
        "train_X_temp = select(train_X_copy)\n",
        "test_X_temp = select(test_X_copy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtYpm5wNWSt-"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6zB_fRSWRME",
        "outputId": "5d1e00df-5b02-4b2a-c482-336223ebcc6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_X_temp, test_X_temp = normalize(train_X_temp, test_X_temp)\n",
        "\n",
        "display(train_X_temp.head())\n",
        "print(train_X_temp.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cont_antonym</th>\n",
              "      <th>cont_antonym_stem</th>\n",
              "      <th>p_len</th>\n",
              "      <th>h_len</th>\n",
              "      <th>p_word_len</th>\n",
              "      <th>h_word_len</th>\n",
              "      <th>p_unique_word_len</th>\n",
              "      <th>h_unique_word_len</th>\n",
              "      <th>i_len</th>\n",
              "      <th>p_contains_neg</th>\n",
              "      <th>h_contains_neg</th>\n",
              "      <th>i_contains_neg</th>\n",
              "      <th>p_contains_pos</th>\n",
              "      <th>h_contains_pos</th>\n",
              "      <th>i_contains_pos</th>\n",
              "      <th>ph_len_rat</th>\n",
              "      <th>ph_word_len_rat</th>\n",
              "      <th>ph_unique_word_len_rat</th>\n",
              "      <th>ip_unique_word_len_rat</th>\n",
              "      <th>ih_unique_word_len_rat</th>\n",
              "      <th>p_max</th>\n",
              "      <th>p_min</th>\n",
              "      <th>p_mean</th>\n",
              "      <th>h_max</th>\n",
              "      <th>h_min</th>\n",
              "      <th>h_mean</th>\n",
              "      <th>ph_max</th>\n",
              "      <th>ph_min</th>\n",
              "      <th>ph_mean</th>\n",
              "      <th>ratio</th>\n",
              "      <th>partial_ratio</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>is_ordered_subs_num</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.340015</td>\n",
              "      <td>1.520432</td>\n",
              "      <td>-0.203206</td>\n",
              "      <td>-0.665672</td>\n",
              "      <td>-0.162734</td>\n",
              "      <td>-0.635809</td>\n",
              "      <td>0.028820</td>\n",
              "      <td>-0.633840</td>\n",
              "      <td>-0.278203</td>\n",
              "      <td>-0.36442</td>\n",
              "      <td>-0.549523</td>\n",
              "      <td>-0.183888</td>\n",
              "      <td>-0.405554</td>\n",
              "      <td>3.135429</td>\n",
              "      <td>-0.178638</td>\n",
              "      <td>0.103244</td>\n",
              "      <td>0.104849</td>\n",
              "      <td>0.331684</td>\n",
              "      <td>-0.450297</td>\n",
              "      <td>0.549705</td>\n",
              "      <td>-1.019765</td>\n",
              "      <td>-0.611149</td>\n",
              "      <td>-1.028028</td>\n",
              "      <td>-0.463279</td>\n",
              "      <td>-0.374057</td>\n",
              "      <td>-0.573416</td>\n",
              "      <td>0.925638</td>\n",
              "      <td>0.549489</td>\n",
              "      <td>0.886898</td>\n",
              "      <td>-0.716179</td>\n",
              "      <td>-0.765537</td>\n",
              "      <td>-0.332903</td>\n",
              "      <td>-0.571903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.340015</td>\n",
              "      <td>-0.425235</td>\n",
              "      <td>-0.203206</td>\n",
              "      <td>-0.758516</td>\n",
              "      <td>-0.162734</td>\n",
              "      <td>-0.347794</td>\n",
              "      <td>0.028820</td>\n",
              "      <td>-0.314379</td>\n",
              "      <td>-0.594123</td>\n",
              "      <td>-0.36442</td>\n",
              "      <td>-0.549523</td>\n",
              "      <td>-0.183888</td>\n",
              "      <td>-0.405554</td>\n",
              "      <td>-0.318936</td>\n",
              "      <td>-0.178638</td>\n",
              "      <td>0.185942</td>\n",
              "      <td>-0.084313</td>\n",
              "      <td>0.060581</td>\n",
              "      <td>-0.730546</td>\n",
              "      <td>-0.739556</td>\n",
              "      <td>-0.831257</td>\n",
              "      <td>-0.202156</td>\n",
              "      <td>-0.766581</td>\n",
              "      <td>-0.739276</td>\n",
              "      <td>-0.374057</td>\n",
              "      <td>-0.923100</td>\n",
              "      <td>0.621845</td>\n",
              "      <td>0.141917</td>\n",
              "      <td>0.520869</td>\n",
              "      <td>-0.516997</td>\n",
              "      <td>0.008947</td>\n",
              "      <td>-0.826233</td>\n",
              "      <td>1.221225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.340015</td>\n",
              "      <td>3.466098</td>\n",
              "      <td>-0.203206</td>\n",
              "      <td>2.491024</td>\n",
              "      <td>-0.162734</td>\n",
              "      <td>2.820374</td>\n",
              "      <td>0.028820</td>\n",
              "      <td>3.199695</td>\n",
              "      <td>3.196916</td>\n",
              "      <td>-0.36442</td>\n",
              "      <td>-0.549523</td>\n",
              "      <td>-0.183888</td>\n",
              "      <td>-0.405554</td>\n",
              "      <td>-0.318936</td>\n",
              "      <td>-0.178638</td>\n",
              "      <td>-0.815974</td>\n",
              "      <td>-0.777906</td>\n",
              "      <td>-0.933464</td>\n",
              "      <td>2.632437</td>\n",
              "      <td>0.823185</td>\n",
              "      <td>0.394041</td>\n",
              "      <td>-0.202156</td>\n",
              "      <td>0.335228</td>\n",
              "      <td>2.848693</td>\n",
              "      <td>-0.374057</td>\n",
              "      <td>3.044466</td>\n",
              "      <td>0.621845</td>\n",
              "      <td>0.141917</td>\n",
              "      <td>0.520869</td>\n",
              "      <td>2.802706</td>\n",
              "      <td>2.177501</td>\n",
              "      <td>2.380415</td>\n",
              "      <td>1.221225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.340015</td>\n",
              "      <td>-0.425235</td>\n",
              "      <td>-0.559879</td>\n",
              "      <td>-0.665672</td>\n",
              "      <td>-0.419806</td>\n",
              "      <td>-0.347794</td>\n",
              "      <td>-0.571931</td>\n",
              "      <td>-0.314379</td>\n",
              "      <td>0.037717</td>\n",
              "      <td>-0.36442</td>\n",
              "      <td>-0.549523</td>\n",
              "      <td>-0.183888</td>\n",
              "      <td>2.465766</td>\n",
              "      <td>-0.318936</td>\n",
              "      <td>-0.178638</td>\n",
              "      <td>-0.298431</td>\n",
              "      <td>-0.311307</td>\n",
              "      <td>-0.427405</td>\n",
              "      <td>0.550590</td>\n",
              "      <td>0.666911</td>\n",
              "      <td>-0.171481</td>\n",
              "      <td>-0.611149</td>\n",
              "      <td>-0.754132</td>\n",
              "      <td>-0.187281</td>\n",
              "      <td>-0.374057</td>\n",
              "      <td>-0.250631</td>\n",
              "      <td>0.115522</td>\n",
              "      <td>0.549489</td>\n",
              "      <td>0.698799</td>\n",
              "      <td>0.943672</td>\n",
              "      <td>0.086395</td>\n",
              "      <td>0.592092</td>\n",
              "      <td>0.100520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.340015</td>\n",
              "      <td>-0.425235</td>\n",
              "      <td>-0.559879</td>\n",
              "      <td>-1.315580</td>\n",
              "      <td>-0.419806</td>\n",
              "      <td>-1.211839</td>\n",
              "      <td>-0.571931</td>\n",
              "      <td>-1.272763</td>\n",
              "      <td>-1.225963</td>\n",
              "      <td>-0.36442</td>\n",
              "      <td>-0.549523</td>\n",
              "      <td>-0.183888</td>\n",
              "      <td>2.465766</td>\n",
              "      <td>-0.318936</td>\n",
              "      <td>-0.178638</td>\n",
              "      <td>0.340598</td>\n",
              "      <td>0.369676</td>\n",
              "      <td>0.426570</td>\n",
              "      <td>-1.050830</td>\n",
              "      <td>-1.091173</td>\n",
              "      <td>-1.019765</td>\n",
              "      <td>-0.611149</td>\n",
              "      <td>-1.028028</td>\n",
              "      <td>-1.567269</td>\n",
              "      <td>-0.374057</td>\n",
              "      <td>-1.595568</td>\n",
              "      <td>0.520580</td>\n",
              "      <td>0.549489</td>\n",
              "      <td>0.597125</td>\n",
              "      <td>-0.915362</td>\n",
              "      <td>-1.385124</td>\n",
              "      <td>-1.134565</td>\n",
              "      <td>0.225043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    cont_antonym  cont_antonym_stem  ...  token_sort_ratio  is_ordered_subs_num\n",
              "id                                   ...                                       \n",
              "0      -0.340015           1.520432  ...         -0.332903            -0.571903\n",
              "1      -0.340015          -0.425235  ...         -0.826233             1.221225\n",
              "2      -0.340015           3.466098  ...          2.380415             1.221225\n",
              "3      -0.340015          -0.425235  ...          0.592092             0.100520\n",
              "4      -0.340015          -0.425235  ...         -1.134565             0.225043\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(6726, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqxgnT1DhvrG"
      },
      "source": [
        "def i2l(i):\n",
        "    if i > 1:\n",
        "        return 'entailment'\n",
        "    if i > -1:\n",
        "        return 'neutral'\n",
        "    return 'contradiction'\n",
        "\n",
        "def list_i2l(i):\n",
        "    return [i2l(ii) for ii in i]\n",
        "\n",
        "def l2i(l):\n",
        "    if l == 'entailment':\n",
        "        return 3\n",
        "    if l == 'neutral':\n",
        "        return 0\n",
        "    if l == 'contradiction':\n",
        "        return -3\n",
        "    assert (False)\n",
        "\n",
        "def list_l2i(l):\n",
        "    return [l2i(ll) for ll in l]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05q6_ABMN-5g"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P2ed36vCmyU",
        "outputId": "59d56e95-e737-4044-bd68-ae92a3ea379d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from catboost import CatBoostClassifier, Pool, cv\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(21) \n",
        "clfs = [\n",
        "        KNeighborsClassifier(),\n",
        "        SVC(),\n",
        "        SVC(kernel=\"linear\", C=0.025),\n",
        "        DecisionTreeClassifier(max_depth=5),\n",
        "        RandomForestClassifier(),\n",
        "        # RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "        MLPClassifier(alpha=1, max_iter=1000),\n",
        "        AdaBoostClassifier(),\n",
        "        GaussianNB(),\n",
        "        QuadraticDiscriminantAnalysis(),\n",
        "        # CatBoostClassifier(verbose=0),\n",
        "# \n",
        "        # LinearRegression(),\n",
        "        # KNeighborsRegressor(),\n",
        "        # SVR(),\n",
        "        # SVR(kernel=\"linear\", C=0.025),\n",
        "        # RandomForestRegressor(),\n",
        "        # RandomForestRegressor(max_depth=5, n_estimators=10, max_features=1),\n",
        "        # MLPRegressor(alpha=1, max_iter=1000),\n",
        "        # AdaBoostRegressor(),\n",
        "\n",
        "\n",
        "        ]\n",
        "# \n",
        "skf = StratifiedKFold(n_splits=2)\n",
        "max_clf = None\n",
        "max_score = 0\n",
        "maxs_acc = 0\n",
        "for clf in clfs:\n",
        "\n",
        "    X = train_X_temp\n",
        "    y = train_y\n",
        "    score = []\n",
        "    acc = []\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
        "        y_train, y_test = y.values[train_index], y.values[test_index]\n",
        "        # y_train = list_l2i(y_train)\n",
        "        clf.fit(X_train, y_train)\n",
        "        pred = clf.predict(X_test)\n",
        "        # pred = list_i2l(pred)\n",
        "        score.append(f1_score(y_test, pred, average='macro'))\n",
        "        acc.append(accuracy_score(y_test, pred))\n",
        "\n",
        "    # score = cross_val_score(clf, train_X_temp, train_y, cv=5, scoring='f1_macro').mean()\n",
        "    score = np.array(score).mean()\n",
        "    if score >= max_score:\n",
        "        max_score = score\n",
        "        max_clf = clf\n",
        "        maxs_acc = np.array(acc).mean()\n",
        "    print(clf.__class__.__name__, score)\n",
        "\n",
        "print()\n",
        "print('max:', max_clf, )\n",
        "print('f1:', max_score)\n",
        "print('acc:', maxs_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier 0.5390303233847193\n",
            "SVC 0.6161345173415849\n",
            "SVC 0.6189076069160607\n",
            "DecisionTreeClassifier 0.6091090339052578\n",
            "RandomForestClassifier 0.6031292927994893\n",
            "MLPClassifier 0.618345006554939\n",
            "AdaBoostClassifier 0.611669445383537\n",
            "GaussianNB 0.5786675720094479\n",
            "QuadraticDiscriminantAnalysis 0.5587996605201253\n",
            "\n",
            "max: SVC(C=0.025, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "f1: 0.6189076069160607\n",
            "acc: 0.6181980374665477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKQoqVcExDsd",
        "outputId": "61216729-b8f4-463a-81d8-9850d296fa39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        train_X_temp, train_y, test_size = 0.2)\n",
        "\n",
        "#\n",
        "# y_train = list_l2i(y_train)\n",
        "\n",
        "max_clf.fit(X_train, y_train)\n",
        "preds = max_clf.predict(X_test)\n",
        "\n",
        "#\n",
        "# preds = list_i2l(preds)\n",
        "\n",
        "dff = pd.DataFrame()\n",
        "df_preds = []\n",
        "truths = []\n",
        "hipos = []\n",
        "prems = []\n",
        "for enum_idx in range(len(preds)):\n",
        "    pred = preds[enum_idx]\n",
        "    truth = y_test.values[enum_idx]\n",
        "    if pred != truth:\n",
        "        idx = y_test.index.values[enum_idx]\n",
        "        hipos.append(train.iloc[idx]['hipotesis'])\n",
        "        prems.append(train.iloc[idx]['premis'])\n",
        "        truths.append(truth)\n",
        "        df_preds.append(pred)\n",
        "dff['premis'] = prems\n",
        "dff['hipotesis'] = hipos\n",
        "dff['preds'] = df_preds\n",
        "dff['truths'] = truths\n",
        "\n",
        "dff['len'] = dff['hipotesis'].apply(len) + dff['premis'].apply(len)\n",
        "dff = dff.sort_values(by='len').drop('len',1)\n",
        "\n",
        "pd.set_option('display.max_colwidth', 0)\n",
        "display(dff.head(30))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premis</th>\n",
              "      <th>hipotesis</th>\n",
              "      <th>preds</th>\n",
              "      <th>truths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>Air Terjun Pucuk di Sambangan memiliki ketinggian 16 meter .</td>\n",
              "      <td>Air Terjun di Sambangan indah .</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>Pantai Melasti ini berada tak jauh dari Tanah Lot.</td>\n",
              "      <td>Pantai Melasti berada sebelum Tanah Lot .</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>Pantai Melasti ini berada tak jauh dari Tanah Lot.</td>\n",
              "      <td>Tanah Lot tidak jauh dari Pantai Melasti .</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>Aliansi ini adalah gabungan Partai Demokratik dan PNL .</td>\n",
              "      <td>PNL hanya bergabung dengan Partai Hongaria.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Nn. Hopley menambahkan: \"Duri dalam risiko politik tidak boleh diabaikan.\"</td>\n",
              "      <td>Nn. Hopley adalah warga Duri.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>Anda dapat mengunjungi Warso Farm yang menawarkan wisata petik durian.</td>\n",
              "      <td>Terdapat pohon durian di Warso Farm</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>\" Saya menyukai segala hal tentang dia , jadi saya selalu ingin bekerja dengannya .</td>\n",
              "      <td>Saya selalu menyukai dia</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>Pada bulan Mei 2011 lalu , ia memutuskan membeli 51 % saham Mandala Airlines .</td>\n",
              "      <td>61 % saham Manda dibeli olehnya</td>\n",
              "      <td>neutral</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Ia belum pernah mendapat kap , tetapi telah tampil membela sebanyak empat kali sejak 2006 .</td>\n",
              "      <td>kap didapatkan ia .</td>\n",
              "      <td>entailment</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>Pura Parahyangan diketahui merupakan pura terbesar yang berada di Pulau Jawa.</td>\n",
              "      <td>Hanya ada satu Pura di Pulau Jawa</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>'Hubungan keduanya tak akur karena Ellen tak pernah punya waktu untuk Kiara .'</td>\n",
              "      <td>Ellen tidak punya waktu untuk Kiara</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>Perang Inggris-Burma Pertama berlangsung dari tahun 1823 hingga 1826 .</td>\n",
              "      <td>Perang Inggris-Burma terjadi selama 3 tahun.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>Menurut Rhodes , keputusan itu menjadi preseden buruk bagi pembuat musik lain .</td>\n",
              "      <td>Rhodes adalah seorang pembuat musik.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>Cara terbaik untuk tetap terhidrasi adalah minum air sepanjang malam .</td>\n",
              "      <td>Minum air sepanjang malam mencegah dehidrasi.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>Letaknya menggantung dengan 2 - 4 bunga yang bertangkai , dan kuncupnya berbentuk sabit .</td>\n",
              "      <td>Kuncupnya berbentuk bulat .</td>\n",
              "      <td>neutral</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Dalam foto-foto yang dirilis tersebut , tidak ada satu pun dari mereka yang menggunakan kacamata .</td>\n",
              "      <td>Foto belum dirilis.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>'Georgia tidak mengakui status Ossetia Selatan sebagai suatu entitas tersendiri '</td>\n",
              "      <td>Georgia mengakui status Ossetia Selatan</td>\n",
              "      <td>entailment</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>Mulai 1 Januari akan ada kenaikan harga bensin dan solar .</td>\n",
              "      <td>Harga bensin akan naik seribu rupiah mulai tanggal 1 Januari .</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>Ezra memang belum mengumumkan kapan album baru bandnya tersebut akan dirilis .</td>\n",
              "      <td>Sebuah album baru akan dirlis oleh band Ezra</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>Pohon ini mirip dengan Telopea, yang masih dalam kerabat dekat dengan tanaman ini.</td>\n",
              "      <td>Pohon ini sangat berbeda dengan Telopea.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>Pura Besakih merupakan tempat sembayang para umat Hindu di Bali .</td>\n",
              "      <td>Pura Besakih adalah tempat sembayang umat Hindu di Jawa .</td>\n",
              "      <td>entailment</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Saham berjangka A.S. melonjak lebih dari 1 % , berdampingan dengan pasar Eropa .</td>\n",
              "      <td>Saham berjangka A.S. mengalami peningkatan.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>Uni Soviet adalah negara sosialis yang pernah ada antara tahun 1922 â 1991 di Eurasia .</td>\n",
              "      <td>Uni Soviet adalah negara komunis .</td>\n",
              "      <td>neutral</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>Monaco dan Madrid memang sedang memimpin klasemen Ligue 1 Prancis dan La Liga Spanyol .</td>\n",
              "      <td>Madrid memenangkan La Liga Spanyol .</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>Jumlah karyawannya saja 4.300 orang dengan 600 pilot , tapi hanya mengoperasikan 35 pesawat .</td>\n",
              "      <td>Mereka memiliki ribuan karyawan</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>Merek-merek minuman sehat yang bagus adalah You C , Hydro Coco , dan Cap Kaki Tiga .</td>\n",
              "      <td>Hydro Coco adalah salah satu merek minuman</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>Gue sama istri bukan tipe orang yang suka jalan-jalan pas orang liburan .</td>\n",
              "      <td>Gue dan istri memiliki kesamaan dalam hal jalan-jalan</td>\n",
              "      <td>neutral</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>Danau Buyan Wanagiri ini jaraknya sekitar 11 kilometer dari Desa Munduk ke arah timur laut .</td>\n",
              "      <td>Buyan Wanagiri adalan nama desa .</td>\n",
              "      <td>neutral</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>Anda juga dapat mempelajari sejarah dan budaya Hindu yang kental di Pura Parahyangan ini.</td>\n",
              "      <td>Terdapat pengajar di Pura Parahyangan</td>\n",
              "      <td>entailment</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>'Georgia tidak mengakui status Ossetia Selatan sebagai suatu entitas tersendiri '</td>\n",
              "      <td>Georgia tidak mengakui status Ossetia Selatan</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                 premis  ...         truths\n",
              "400  Air Terjun Pucuk di Sambangan memiliki ketinggian 16 meter .                                        ...  neutral      \n",
              "276  Pantai Melasti ini berada tak jauh dari Tanah Lot.                                                  ...  neutral      \n",
              "83   Pantai Melasti ini berada tak jauh dari Tanah Lot.                                                  ...  entailment   \n",
              "202  Aliansi ini adalah gabungan Partai Demokratik dan PNL .                                             ...  contradiction\n",
              "95   Nn. Hopley menambahkan: \"Duri dalam risiko politik tidak boleh diabaikan.\"                          ...  neutral      \n",
              "305  Anda dapat mengunjungi Warso Farm yang menawarkan wisata petik durian.                              ...  neutral      \n",
              "450  \" Saya menyukai segala hal tentang dia , jadi saya selalu ingin bekerja dengannya .                 ...  neutral      \n",
              "314  Pada bulan Mei 2011 lalu , ia memutuskan membeli 51 % saham Mandala Airlines .                      ...  contradiction\n",
              "498  Ia belum pernah mendapat kap , tetapi telah tampil membela sebanyak empat kali sejak 2006 .         ...  contradiction\n",
              "287  Pura Parahyangan diketahui merupakan pura terbesar yang berada di Pulau Jawa.                       ...  neutral      \n",
              "285  'Hubungan keduanya tak akur karena Ellen tak pernah punya waktu untuk Kiara .'                      ...  entailment   \n",
              "174  Perang Inggris-Burma Pertama berlangsung dari tahun 1823 hingga 1826 .                              ...  entailment   \n",
              "431  Menurut Rhodes , keputusan itu menjadi preseden buruk bagi pembuat musik lain .                     ...  neutral      \n",
              "275  Cara terbaik untuk tetap terhidrasi adalah minum air sepanjang malam .                              ...  entailment   \n",
              "171  Letaknya menggantung dengan 2 - 4 bunga yang bertangkai , dan kuncupnya berbentuk sabit .           ...  contradiction\n",
              "30   Dalam foto-foto yang dirilis tersebut , tidak ada satu pun dari mereka yang menggunakan kacamata .  ...  contradiction\n",
              "38   'Georgia tidak mengakui status Ossetia Selatan sebagai suatu entitas tersendiri '                   ...  contradiction\n",
              "410  Mulai 1 Januari akan ada kenaikan harga bensin dan solar .                                          ...  neutral      \n",
              "337  Ezra memang belum mengumumkan kapan album baru bandnya tersebut akan dirilis .                      ...  entailment   \n",
              "467  Pohon ini mirip dengan Telopea, yang masih dalam kerabat dekat dengan tanaman ini.                  ...  contradiction\n",
              "299  Pura Besakih merupakan tempat sembayang para umat Hindu di Bali .                                   ...  contradiction\n",
              "62   Saham berjangka A.S. melonjak lebih dari 1 % , berdampingan dengan pasar Eropa .                    ...  entailment   \n",
              "399  Uni Soviet adalah negara sosialis yang pernah ada antara tahun 1922 â 1991 di Eurasia .           ...  contradiction\n",
              "128  Monaco dan Madrid memang sedang memimpin klasemen Ligue 1 Prancis dan La Liga Spanyol .             ...  neutral      \n",
              "397  Jumlah karyawannya saja 4.300 orang dengan 600 pilot , tapi hanya mengoperasikan 35 pesawat .       ...  entailment   \n",
              "205  Merek-merek minuman sehat yang bagus adalah You C , Hydro Coco , dan Cap Kaki Tiga .                ...  entailment   \n",
              "325  Gue sama istri bukan tipe orang yang suka jalan-jalan pas orang liburan .                           ...  entailment   \n",
              "328  Danau Buyan Wanagiri ini jaraknya sekitar 11 kilometer dari Desa Munduk ke arah timur laut .        ...  contradiction\n",
              "420  Anda juga dapat mempelajari sejarah dan budaya Hindu yang kental di Pura Parahyangan ini.           ...  neutral      \n",
              "395  'Georgia tidak mengakui status Ossetia Selatan sebagai suatu entitas tersendiri '                   ...  entailment   \n",
              "\n",
              "[30 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5lxGy604adW",
        "outputId": "779caffb-c4ce-4b3d-9b35-fc9f374ac159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "train[train['hipotesis'] == 'Raja masih hidup.']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premis</th>\n",
              "      <th>hipotesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3042</th>\n",
              "      <td>Dua bayi almarhum Raja, Diana dan Suharna, diculik.</td>\n",
              "      <td>Raja masih hidup.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   premis  ...          label\n",
              "id                                                         ...               \n",
              "3042  Dua bayi almarhum Raja, Diana dan Suharna, diculik.  ...  contradiction\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-MQt_obvGrb",
        "outputId": "cb5ccfa3-9fec-42eb-d1ed-9595c33d9ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "r = permutation_importance(max_clf, train_X_temp, train_y,\n",
        "                           n_repeats=10,\n",
        "                           random_state=0)\n",
        "\n",
        "imp_df = pd.DataFrame()\n",
        "columns = []\n",
        "imp_means = []\n",
        "imp_stds = []\n",
        "for i in r.importances_mean.argsort()[::-1]:\n",
        "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
        "        columns.append(train_X_temp.columns[i]),\n",
        "        imp_means.append(r.importances_mean[i]),\n",
        "        imp_stds.append(r.importances_std[i])\n",
        "imp_df['feature'] = columns\n",
        "imp_df['importance mean'] = imp_means\n",
        "imp_df['importance std'] = imp_stds\n",
        "imp_df = imp_df.sort_values(by='importance mean',ascending=False)\n",
        "display(imp_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance mean</th>\n",
              "      <th>importance std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>h_contains_neg</td>\n",
              "      <td>0.179676</td>\n",
              "      <td>0.005940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ih_unique_word_len_rat</td>\n",
              "      <td>0.046670</td>\n",
              "      <td>0.004006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>h_max</td>\n",
              "      <td>0.030048</td>\n",
              "      <td>0.003167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>h_word_len</td>\n",
              "      <td>0.023075</td>\n",
              "      <td>0.001701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>h_mean</td>\n",
              "      <td>0.019269</td>\n",
              "      <td>0.003164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>token_sort_ratio</td>\n",
              "      <td>0.012013</td>\n",
              "      <td>0.002139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>h_unique_word_len</td>\n",
              "      <td>0.010095</td>\n",
              "      <td>0.001373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>h_len</td>\n",
              "      <td>0.003048</td>\n",
              "      <td>0.001355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>p_mean</td>\n",
              "      <td>0.002632</td>\n",
              "      <td>0.001173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  feature  importance mean  importance std\n",
              "0  h_contains_neg          0.179676         0.005940      \n",
              "1  ih_unique_word_len_rat  0.046670         0.004006      \n",
              "2  h_max                   0.030048         0.003167      \n",
              "3  h_word_len              0.023075         0.001701      \n",
              "4  h_mean                  0.019269         0.003164      \n",
              "5  token_sort_ratio        0.012013         0.002139      \n",
              "6  h_unique_word_len       0.010095         0.001373      \n",
              "7  h_len                   0.003048         0.001355      \n",
              "8  p_mean                  0.002632         0.001173      "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hNgAq7nwwF_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTk2h1rdnIkE",
        "outputId": "b18c46b4-f449-4f91-d3f8-6f29f01764e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        train_X_temp, train_y, train_size=0.2)\n",
        "max_clf.fit(X_train, y_train)\n",
        "fig, ax = plt.subplots(figsize=(7, 7))\n",
        "plot_confusion_matrix(max_clf, X_test, y_test, ax=ax, values_format = '')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk9x5JHSnOQ3",
        "outputId": "3979a985-d615-4c95-93ec-ab1409c7b477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        }
      },
      "source": [
        "forest = RandomForestClassifier()\n",
        "\n",
        "forest.fit(train_X_temp, train_y)\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(train_X_temp.shape[1]):\n",
        "    # print(\"%d. feature %s (%f)\" % (f + 1, train_X_temp.columns[indices[f]], importances[indices[f]]))\n",
        "    print(\"'{}',\".format(train_X_temp.columns[indices[f]]))\n",
        "\n",
        "# Plot the impurity-based feature importances of the forest\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(train_X_temp.shape[1]), importances[indices],\n",
        "        color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(train_X_temp.shape[1]), indices)\n",
        "plt.xlim([-1, train_X_temp.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "'h_contains_neg',\n",
            "'ih_unique_word_len_rat',\n",
            "'partial_ratio',\n",
            "'ph_len_rat',\n",
            "'ip_unique_word_len_rat',\n",
            "'p_mean',\n",
            "'ratio',\n",
            "'h_len',\n",
            "'ph_mean',\n",
            "'token_sort_ratio',\n",
            "'h_mean',\n",
            "'p_len',\n",
            "'ph_word_len_rat',\n",
            "'ph_unique_word_len_rat',\n",
            "'is_ordered_subs_num',\n",
            "'p_max',\n",
            "'ph_max',\n",
            "'p_word_len',\n",
            "'p_unique_word_len',\n",
            "'ph_min',\n",
            "'i_len',\n",
            "'h_max',\n",
            "'p_min',\n",
            "'h_word_len',\n",
            "'h_unique_word_len',\n",
            "'cont_antonym_stem',\n",
            "'cont_antonym',\n",
            "'p_contains_neg',\n",
            "'h_min',\n",
            "'h_contains_pos',\n",
            "'p_contains_pos',\n",
            "'i_contains_neg',\n",
            "'i_contains_pos',\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rky5625wDh7C"
      },
      "source": [
        "# model = RandomForestClassifier()\n",
        "model = max_clf\n",
        "\n",
        "# \n",
        "# train_y = list_l2i(train_y)\n",
        "\n",
        "model.fit(train_X_temp, train_y)\n",
        "\n",
        "\n",
        "pred = model.predict(test_X_temp)\n",
        "\n",
        "#\n",
        "# pred = list_i2l(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NQ2kNBYFDVV"
      },
      "source": [
        "submit = pd.DataFrame(index=test.index)\n",
        "submit['label'] = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2O_8bfwF3-b",
        "outputId": "aef0a399-d129-4cb8-f3d5-de3f66a74382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "print(submit.shape)\n",
        "display(submit.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6993, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            label\n",
              "id               \n",
              "0   neutral      \n",
              "1   entailment   \n",
              "2   entailment   \n",
              "3   neutral      \n",
              "4   contradiction"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RfiGESwEYnN"
      },
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone    \n",
        "\n",
        "jkt_time = datetime.now(timezone('Asia/Jakarta'))\n",
        "st = jkt_time.strftime('%Y-%m-%d_%H-%M-%S')\n",
        "submit.to_csv(f'{drivedir}submit_{st}.csv', header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTK1BvbaZtBD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}